% !TeX spellcheck = es_ES
\documentclass[a4paper, 11pt]{article}
\usepackage[table,xcdraw]{xcolor}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage[spanish, activeacute]{babel} %Definir idioma español
\usepackage[utf8]{inputenc} %Codificacion utf-8

\usepackage{geometry}
\geometry{left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm}

\DeclareMathOperator*{\argmax}{arg\,max}

\title{\Large{\textbf{Detección de caras basada en Redes Neuronales}}}

\author{\textit{Francisco Rubin Capalbo}\\
		Universidad Politécnica de Valencia }

\date{\today}

\begin{document}
    
    \maketitle
    \section{Introducción}
    	Este trabajo consiste en el diseño y la implementación de un detector de caras basado en redes neuronales. El detector se puede dividir en dos partes igual de importantes: el clasificador de caras y el extractor de crops a clasificar. \\
    \section{Dataset}
		El dataset necesario para entrenar el clasificador de caras consiste en un conjunto de imágenes que contienen una cara (centrada, con un pequeño margen) y otro conjunto igual de grande que no contiene ninguna. 
		
		\subsection{No-caras}
		Para obtener el conjunto de no-caras\cite{script-no-caras}, he empleado varias herramientas. Por un lado, he descargado imágenes en masa de una API de google imágenes. He utilizado keywords con una gran probabilidad de representar imágenes sin caras, como ``carretera``, ``espacio``, ``texturas``, etc. \\
		
		 A continuación, he utilizado un detector de caras de OpenCV basado en filtros Haar, para descartar las imágenes contenedoras de una o más caras. De las imágenes resultantes he extraído crops de ancho y alto aleatorios en posiciones aleatorias. En total, el dataset de no-caras está compuesto por unas 150 mil imágenes. 
		 
		 \subsection{Caras}
		 Para el dataset de caras he utilizado CelebA\cite{celeb-a}. El problema de este dataset es que las caras que contiene no están centradas, y en algunas imágenes aparece el cuerpo entero. Para resolver este problema, he vuelto a recurrir a el detector de caras de OpenCV\cite{script-caras}, para detectar una cara por imagen y extraerla a un archivo a parte. En total, he conseguido unas 150 mil caras. 

		\subsection{Nota}
		Un detalle que me preocupa del método utilizado para obtener el dataset, es que depende completamente de el detector implementado en OpenCV con filtros Haar. Esto podría implicar que nuestro modelo no puede aprender de caras extrañas que los filtros Haar no detectan, así poniendo un techo a la precisión obtenida. Por otro lado, si los filtros Haar detectan caras dónde no las hay, éstas serán utilizadas incorrectamente en nuestro modelo. A pesar de esto, no he encontrado otra manera más efectiva de obtener el Dataset.
	\section{Clasificador}
		El objetivo del clasificador\cite{classifier-training} es decidir si la imagen que recibe como input es una cara o no. Es un clasificador binario (cara / no cara), por lo cual utilizamos la función de pérdida 'Binary Cross Entropy'.
		
		\subsection{Data Augmentation}
			Una manera muy efectiva de que el clasificador generalice mejor es haciendo data augmentation. Para este problema he aplicado rotación, traslación, escalado y flip horizontal de manera aleatoria. De especial importancia es la rotación, ya que la mayoría de las caras del dataset aparecen en posición vertical, y queremos que el clasificador sepa reconocer caras en cualquier orientación.
			
		\subsection{Normalización de datos}
			Todas las imágenes pasadas al clasificador son normalizadas de la misma manera. Primero se convierten a blanco y negro y se aplica una normalización de color (x - mean / std). Por último, se escalan a un tamaño de 24x24 píxeles.

		\subsection{Modelos}
			Todos los modelos utilizados están compuestos por una parte de extracción de características, compuesta principalmente por capas convolucionales, y otra de clasificación, compuesta por capas fully-connected.  \\
			
			He hecho pruebas con diferentes modelos\cite{compare-models}, utilizando un dataset pequeño (5\% del total de imágenes) para poder hacer varias pruebas rápidamente. Después de entrenar todos los modelos, he hecho una comparación de ellos basándome en Accuracy obtenido y en el tiempo que tarda en clasificar 1000 muestras. Ambos valores son importantes para nuestro clasificador. \\
			
			Estos son los resultados obtenidos:
			
			\begin{table}[htb!]
				\centering
				\caption{Evaluación Modelos}
				\label{evaluacion-modelos}
				\begin{tabular}{|c|c|c|}
					\hline
					\textbf{Modelo}                                                 & \textbf{Accuracy} & \textbf{Tiempo (segundos)} \\ \hline
					Modelo 1                                                            & 99.766                & 0.316               \\ \hline
					Modelo 2                                                              & 99.732                & 0.295              \\ \hline
					Modelo 3                                                   & 99.465                & 0.277                \\ \hline
					\textbf{Modelo 4}                                                    & \textbf{99.699}             & \textbf{0.271}               \\ \hline
					Modelo 5                                                    & 99.532             & 0.293               \\ \hline
					Modelo 6                                                    & 99.766             & 0.393               \\ \hline
				\end{tabular}
			\end{table}
			
			En el apendice A muestro la descripción de cada uno de los modelos. \\
			
			En la Figura 1 vemos el loss obtenido por epoch en el modelo elegido finalmente (Modelo 4) utilizando el dataset completo.
			
					
			\begin{figure}[htb!]
				\begin{minipage}{1\textwidth}
					\centering
					\includegraphics[scale=.5]{pics/model4_losses_per_epoch}
					\caption{Modelo 4: Loss por epoch}
					\label{fig:model4_losses_per_epoch}
				\end{minipage}\hfill
			\end{figure}
			
		\subsection{Detector}
			La función del detector es recibir una imagen de dimensiones desconocidas y devolver la misma imagen con rectángulos en los sitios en los que haya una cara. Sigue cuatro pasos:\\
			
			\begin{enumerate}
				\item Escalar la imagen para alcanzar una anchura y altura máximas si es necesario, para reducir el número de crops. 
				\item Extracción de crops utilizando una ventana en movimiento que da saltos de \textit{index\_increase} píxeles en vertical y horizontal recorriéndose la imagen. Cuando termina de recorrer la imagen completa, aumenta el zoom en z unidades, y vuelve a empezar. Repite hasta que la imagen es demasiado pequeña para realizar el crop.
				\item 
			\end{enumerate}
			- detector
				- downscale image to a max witdth and height to reduce number of crops
				- extracción de crops 
					- mencionar que al pasar los crops a memoria antes de clasificar mejoró de 180 segundos a 10 segundos
				- clasificación de crops en cara/no cara
				- pintar rectángulos en imagen final
				- tutorial de como usar el detector (para q lo pueda probar el profe)
				- explicar efecto de params max image size, 
				
		\subsection{Trabajo Futuro}
			- Trabajo futuro
				- user selective search para selección de crops
				- probar con depthwise separable convolutionals para mejorar velocidad
				- aumentar los saltos de zoom y translation para las seleccion de crops usando el modelo con data augmentation potenciada
				
	\subsection{Apéndice A: Modelos}
		Todos los modelos utilizan como bloque principal de extracción de características un ConvGroup, que está formado por las siguientes capas:
	
	
	\begin{figure}[htb!]
		\begin{minipage}{1\textwidth}
			\centering
			\includegraphics[scale=.5]{pics/convgroup}
		\end{minipage}\hfill
	\end{figure}
	
		Modelos:
	
	\begin{figure}[htb!]
		\begin{minipage}{1\textwidth}
			\centering
			\includegraphics[scale=.5]{pics/model1}
			\caption{Modelo 1}
		\end{minipage}\hfill
	\end{figure}
	
	
	\begin{figure}[htb!]
		\begin{minipage}{1\textwidth}
			\centering
			\includegraphics[scale=.5]{pics/model2}
			\caption{Modelo 2}
		\end{minipage}\hfill
	\end{figure}
	
	
	\begin{figure}[htb!]
		\begin{minipage}{1\textwidth}
			\centering
			\includegraphics[scale=.5]{pics/model3}
			\caption{Modelo 3}
		\end{minipage}\hfill
	\end{figure}
	
	
	\begin{figure}[htb!]
		\begin{minipage}{1\textwidth}
			\centering
			\includegraphics[scale=.5]{pics/model4}
			\caption{Modelo 4}
		\end{minipage}\hfill
	\end{figure}		
	
	
	\begin{figure}[htb!]
		\begin{minipage}{1\textwidth}
			\centering
			\includegraphics[scale=.5]{pics/model5}
			\caption{Modelo 5}
		\end{minipage}\hfill
	\end{figure}
	
	
	\begin{figure}[htb!]
		\begin{minipage}{1\textwidth}
			\centering
			\includegraphics[scale=.5]{pics/model6}
			\caption{Modelo 6}
		\end{minipage}\hfill
	\end{figure}	
		
\begin{thebibliography}{50}
	
	\bibitem{script-no-caras} 
	\href{https://github.com/pancho111203/pytorch-face-detection/blob/master/scripts/get_nofaces.py}{Script obtención no-caras}
	\bibitem{celeb-a} 
	\href{http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html}{CelebA Dataset}
	\bibitem{script-caras} 
	\href{https://github.com/pancho111203/pytorch-face-detection/blob/master/scripts/crop_faces.py}{Script obtención caras}
	\bibitem{classifier-training} 
	\href{https://github.com/pancho111203/pytorch-face-detection/blob/master/face_classifier_training.py}{Entrenamiento clasificador}
	\bibitem{compare-models} 
	\href{https://github.com/pancho111203/pytorch-face-detection/blob/master/compare-models.py}{Script para comparar modelos}
	\bibitem{demo} 
	\href{url }{name}
	\bibitem{demo} 
	\href{url }{name}
	\bibitem{demo} 
	\href{url }{name}
	\bibitem{demo} 
	\href{url }{name}
	\bibitem{demo} 
	\href{url }{name}
\end{thebibliography}

\end{document}